{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17cde0c3",
   "metadata": {},
   "source": [
    "# 오늘은 LeNet 구조를 만들어봅시다\n",
    "\n",
    "\n",
    "LeNet 구조는 CNN이며, 초기에 만들어진 모델입니다. \n",
    "\n",
    "2가지 모델(Sigmoid, ReLU)를 만들어 두 모델의 성능을 비교해봅시다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aff3fd",
   "metadata": {},
   "source": [
    "## 1.우선 필요 라이브러리를 import 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fd17ef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798bac6b",
   "metadata": {},
   "source": [
    "## 2. 딥러닝 모델을 설계할 때 활용하는 장비 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4c9880ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.6.0  Device: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5590af",
   "metadata": {},
   "source": [
    "## 3. MNIST 데이터 다운로드 \n",
    "\n",
    " 1. Training data와 Test data 분리하기\n",
    " \n",
    " 2. Training data를 Training data 와 Validation data로 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "00908077",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5),(0.5)),\n",
    "    ])\n",
    "\n",
    "train_data = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
    "\n",
    "train, val = torch.utils.data.random_split(train_data,[int(len(train_data)*0.95),len(train_data)-int(len(train_data)*0.95)])\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437ffb80",
   "metadata": {},
   "source": [
    "## 4. torch.nn을 이용하여 모델-1 만들기\n",
    "\n",
    "   1) 아래의 그림 중 LeNet 구조를 구현 할 것\n",
    "   \n",
    "   2) Sigmoid 활성화 함수를 이용할 것\n",
    "   \n",
    "   \n",
    "![](Comparison_image_neural_networks.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "defacffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model_1, self).__init__()      \n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, padding=0)\n",
    "        self.fc3=nn.Linear(5*5*16,120)\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.fc2 = nn.Linear(84, 10)\n",
    "    def forward(self,x):\n",
    "        sigmoid = torch.nn.Sigmoid()\n",
    "        x = sigmoid(self.conv1(x))\n",
    "        x = torch.nn.functional.avg_pool2d(x, kernel_size=2,stride=2)\n",
    "        x = sigmoid(self.conv2(x))\n",
    "        x = torch.nn.functional.avg_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = sigmoid(self.fc3(x))\n",
    "        x = sigmoid(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e26eed9",
   "metadata": {},
   "source": [
    "## 5. torch.nn을 이용하여 모델-2 만들기\n",
    "\n",
    "   LeNet 모델에서 ReLU 활성화 함수를 사용하시요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "27ac70af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model_2, self).__init__()              \n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, padding=0)\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.fc2 = nn.Linear(84, 10)\n",
    "        self.fc3=nn.Linear(5*5*16,120)\n",
    "    def forward(self,x):\n",
    "        relu = nn.ReLU()\n",
    "        x = relu(self.conv1(x))\n",
    "        x = torch.nn.functional.avg_pool2d(x, kernel_size=2,stride=2)\n",
    "        x = relu(self.conv2(x))\n",
    "        x = torch.nn.functional.avg_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x= relu(self.fc3(x))\n",
    "        x = relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de556825",
   "metadata": {},
   "source": [
    "## 7. 학습 준비하기\n",
    "\n",
    "1) 1 epoch를 학습할 수 있는 함수 만들기\n",
    "\n",
    "2) Test와 Validation data의 정확도 계산할 수 있는 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "06030b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_epoch(train_loader, network, loss_func, optimizer, epoch):\n",
    "    train_losses = []\n",
    "    train_correct = 0\n",
    "    log_interval = 300\n",
    "    \n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        # 미분값의 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # Forward propagration 계산하기.\n",
    "        outputs = network(image)\n",
    "        \n",
    "        \n",
    "        # Cross_entropy 함수를 적용하여 loss를 구하고 저장하기\n",
    "        loss = loss_func(outputs,label)\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        # training accuracy 정확도 구하기 위해 맞는 샘플 개수 세기\n",
    "        pred = outputs.data.max(1, keepdim=True)[1]\n",
    "        train_correct +=pred.eq(label.view_as(pred)).sum()\n",
    "\n",
    "        # Gradinet 구하기\n",
    "        loss.backward()\n",
    "\n",
    "        # weight값 update 하\n",
    "        optimizer.step()\n",
    "\n",
    "        # 학습 상황 출력\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.2f}%)]\\tLoss: {:.6f}'\n",
    "                  .format(epoch, batch_idx * len(label), len(train_loader.dataset),100. * batch_idx / len(train_loader),\n",
    "                          loss.item()))\n",
    "            \n",
    "    return train_losses, train_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d3c0dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(test_loader, network, loss_func, val = False):\n",
    "    correct = 0\n",
    "    \n",
    "    test_losses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (image, label) in enumerate(test_loader):\n",
    "            image, label = image.to(device), label.to(device)\n",
    "\n",
    "            # Forward propagration 계산하기.\n",
    "            outputs = network(image)\n",
    "            # Cross_entropy 함수를 적용하여 loss를 구하기\n",
    "            loss = loss_func(outputs,label)\n",
    "            test_losses.append(loss.item())\n",
    "\n",
    "            # Batch 별로 정확도 구하기\n",
    "            pred = outputs.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(label.view_as(pred)).sum()\n",
    "\n",
    "        # 전체 정확도 구하기\n",
    "        test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "        #중간결과 출력\n",
    "        if val is True:\n",
    "                print('Validation set: Accuracy: {}/{} ({:.2f}%)\\n'\n",
    "              .format(correct, len(test_loader.dataset),100. * correct / len(test_loader.dataset)))\n",
    "        \n",
    "        else:\n",
    "            print('Test set: Accuracy: {}/{} ({:.2f}%)\\n'\n",
    "                  .format(correct, len(test_loader.dataset),100. * correct / len(test_loader.dataset)))\n",
    "        \n",
    "    return test_losses, test_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d73c53",
   "metadata": {},
   "source": [
    "## 8. 위 정의된 함수로 학습 함수 만들기\n",
    "\n",
    "Adam Optimizer를 사용하여 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "df29783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(network, learning_rate = 0.001):\n",
    "    \n",
    "    epoches = 15\n",
    "    \n",
    "    cls_loss = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=learning_rate)\n",
    "    \n",
    "    train_losses_per_epoch = []\n",
    "    test_losses_per_epoch = []\n",
    "    \n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    \n",
    "    for epoch in range(epoches):\n",
    "                \n",
    "        # 모델를 학습 중이라고 선언하기\n",
    "        network.train()\n",
    "        \n",
    "        train_losses, train_correct = training_epoch(train_loader,network,cls_loss,optimizer, epoch)\n",
    "        \n",
    "        # epoch 별로 loss 평균값, 정확도 구하기\n",
    "        average_loss = np.mean(train_losses)\n",
    "        train_losses_per_epoch.append(average_loss)\n",
    "        \n",
    "        train_accuracy = torch.true_divide(train_correct,len(train_loader.dataset)) * 100\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        \n",
    "        # epoch 별로 정확도 출력\n",
    "        print('\\nTraining set: Accuracy: {}/{} ({:.2f}%)'\n",
    "              .format(train_correct, len(train_loader.dataset),100. * train_correct / len(train_loader.dataset)))\n",
    "\n",
    "        \n",
    "        ### 학습 중에 test 결과 보기\n",
    "        \n",
    "        # 모델 test 중인 것을 선언하기\n",
    "        network.eval()\n",
    "        \n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            test_losses, test_accuracy = test_epoch(val_loader, network, cls_loss, True)\n",
    "\n",
    "        test_losses_per_epoch.append(np.mean(test_losses))\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        test_losses, test_accuracy = test_epoch(test_loader, network, cls_loss, False)\n",
    "        \n",
    "    return train_losses_per_epoch, test_losses_per_epoch, train_accuracies, test_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e1394321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/57000 (0.00%)]\tLoss: 2.366459\n",
      "Train Epoch: 0 [19200/57000 (33.67%)]\tLoss: 1.184591\n",
      "Train Epoch: 0 [38400/57000 (67.34%)]\tLoss: 0.576667\n",
      "\n",
      "Training set: Accuracy: 37767/57000 (66.26%)\n",
      "Validation set: Accuracy: 2736/3000 (91.20%)\n",
      "\n",
      "Train Epoch: 1 [0/57000 (0.00%)]\tLoss: 0.344640\n",
      "Train Epoch: 1 [19200/57000 (33.67%)]\tLoss: 0.298701\n",
      "Train Epoch: 1 [38400/57000 (67.34%)]\tLoss: 0.355750\n",
      "\n",
      "Training set: Accuracy: 52998/57000 (92.98%)\n",
      "Validation set: Accuracy: 2821/3000 (94.03%)\n",
      "\n",
      "Train Epoch: 2 [0/57000 (0.00%)]\tLoss: 0.208146\n",
      "Train Epoch: 2 [19200/57000 (33.67%)]\tLoss: 0.189328\n",
      "Train Epoch: 2 [38400/57000 (67.34%)]\tLoss: 0.241919\n",
      "\n",
      "Training set: Accuracy: 54244/57000 (95.16%)\n",
      "Validation set: Accuracy: 2863/3000 (95.43%)\n",
      "\n",
      "Train Epoch: 3 [0/57000 (0.00%)]\tLoss: 0.138699\n",
      "Train Epoch: 3 [19200/57000 (33.67%)]\tLoss: 0.145489\n",
      "Train Epoch: 3 [38400/57000 (67.34%)]\tLoss: 0.164559\n",
      "\n",
      "Training set: Accuracy: 54905/57000 (96.32%)\n",
      "Validation set: Accuracy: 2884/3000 (96.13%)\n",
      "\n",
      "Train Epoch: 4 [0/57000 (0.00%)]\tLoss: 0.097443\n",
      "Train Epoch: 4 [19200/57000 (33.67%)]\tLoss: 0.125119\n",
      "Train Epoch: 4 [38400/57000 (67.34%)]\tLoss: 0.110109\n",
      "\n",
      "Training set: Accuracy: 55319/57000 (97.05%)\n",
      "Validation set: Accuracy: 2900/3000 (96.67%)\n",
      "\n",
      "Train Epoch: 5 [0/57000 (0.00%)]\tLoss: 0.073571\n",
      "Train Epoch: 5 [19200/57000 (33.67%)]\tLoss: 0.112976\n",
      "Train Epoch: 5 [38400/57000 (67.34%)]\tLoss: 0.071959\n",
      "\n",
      "Training set: Accuracy: 55605/57000 (97.55%)\n",
      "Validation set: Accuracy: 2922/3000 (97.40%)\n",
      "\n",
      "Train Epoch: 6 [0/57000 (0.00%)]\tLoss: 0.057664\n",
      "Train Epoch: 6 [19200/57000 (33.67%)]\tLoss: 0.104784\n",
      "Train Epoch: 6 [38400/57000 (67.34%)]\tLoss: 0.047245\n",
      "\n",
      "Training set: Accuracy: 55790/57000 (97.88%)\n",
      "Validation set: Accuracy: 2927/3000 (97.57%)\n",
      "\n",
      "Train Epoch: 7 [0/57000 (0.00%)]\tLoss: 0.046545\n",
      "Train Epoch: 7 [19200/57000 (33.67%)]\tLoss: 0.098437\n",
      "Train Epoch: 7 [38400/57000 (67.34%)]\tLoss: 0.033629\n",
      "\n",
      "Training set: Accuracy: 55910/57000 (98.09%)\n",
      "Validation set: Accuracy: 2931/3000 (97.70%)\n",
      "\n",
      "Train Epoch: 8 [0/57000 (0.00%)]\tLoss: 0.038798\n",
      "Train Epoch: 8 [19200/57000 (33.67%)]\tLoss: 0.092501\n",
      "Train Epoch: 8 [38400/57000 (67.34%)]\tLoss: 0.026713\n",
      "\n",
      "Training set: Accuracy: 56033/57000 (98.30%)\n",
      "Validation set: Accuracy: 2934/3000 (97.80%)\n",
      "\n",
      "Train Epoch: 9 [0/57000 (0.00%)]\tLoss: 0.034169\n",
      "Train Epoch: 9 [19200/57000 (33.67%)]\tLoss: 0.086465\n",
      "Train Epoch: 9 [38400/57000 (67.34%)]\tLoss: 0.022503\n",
      "\n",
      "Training set: Accuracy: 56116/57000 (98.45%)\n",
      "Validation set: Accuracy: 2939/3000 (97.97%)\n",
      "\n",
      "Train Epoch: 10 [0/57000 (0.00%)]\tLoss: 0.031608\n",
      "Train Epoch: 10 [19200/57000 (33.67%)]\tLoss: 0.080308\n",
      "Train Epoch: 10 [38400/57000 (67.34%)]\tLoss: 0.019498\n",
      "\n",
      "Training set: Accuracy: 56182/57000 (98.56%)\n",
      "Validation set: Accuracy: 2941/3000 (98.03%)\n",
      "\n",
      "Train Epoch: 11 [0/57000 (0.00%)]\tLoss: 0.030140\n",
      "Train Epoch: 11 [19200/57000 (33.67%)]\tLoss: 0.074131\n",
      "Train Epoch: 11 [38400/57000 (67.34%)]\tLoss: 0.017226\n",
      "\n",
      "Training set: Accuracy: 56261/57000 (98.70%)\n",
      "Validation set: Accuracy: 2946/3000 (98.20%)\n",
      "\n",
      "Train Epoch: 12 [0/57000 (0.00%)]\tLoss: 0.028946\n",
      "Train Epoch: 12 [19200/57000 (33.67%)]\tLoss: 0.068164\n",
      "Train Epoch: 12 [38400/57000 (67.34%)]\tLoss: 0.015317\n",
      "\n",
      "Training set: Accuracy: 56333/57000 (98.83%)\n",
      "Validation set: Accuracy: 2949/3000 (98.30%)\n",
      "\n",
      "Train Epoch: 13 [0/57000 (0.00%)]\tLoss: 0.027307\n",
      "Train Epoch: 13 [19200/57000 (33.67%)]\tLoss: 0.062445\n",
      "Train Epoch: 13 [38400/57000 (67.34%)]\tLoss: 0.013980\n",
      "\n",
      "Training set: Accuracy: 56379/57000 (98.91%)\n",
      "Validation set: Accuracy: 2954/3000 (98.47%)\n",
      "\n",
      "Train Epoch: 14 [0/57000 (0.00%)]\tLoss: 0.025067\n",
      "Train Epoch: 14 [19200/57000 (33.67%)]\tLoss: 0.056937\n",
      "Train Epoch: 14 [38400/57000 (67.34%)]\tLoss: 0.014094\n",
      "\n",
      "Training set: Accuracy: 56433/57000 (99.01%)\n",
      "Validation set: Accuracy: 2957/3000 (98.57%)\n",
      "\n",
      "Test set: Accuracy: 59401/60000 (99.00%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network = Model_1().to(device)\n",
    "rlt_const = training(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "64815daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/57000 (0.00%)]\tLoss: 2.304616\n",
      "Train Epoch: 0 [19200/57000 (33.67%)]\tLoss: 0.226073\n",
      "Train Epoch: 0 [38400/57000 (67.34%)]\tLoss: 0.150618\n",
      "\n",
      "Training set: Accuracy: 51939/57000 (91.12%)\n",
      "Validation set: Accuracy: 2895/3000 (96.50%)\n",
      "\n",
      "Train Epoch: 1 [0/57000 (0.00%)]\tLoss: 0.130214\n",
      "Train Epoch: 1 [19200/57000 (33.67%)]\tLoss: 0.084177\n",
      "Train Epoch: 1 [38400/57000 (67.34%)]\tLoss: 0.052022\n",
      "\n",
      "Training set: Accuracy: 55642/57000 (97.62%)\n",
      "Validation set: Accuracy: 2929/3000 (97.63%)\n",
      "\n",
      "Train Epoch: 2 [0/57000 (0.00%)]\tLoss: 0.100458\n",
      "Train Epoch: 2 [19200/57000 (33.67%)]\tLoss: 0.066236\n",
      "Train Epoch: 2 [38400/57000 (67.34%)]\tLoss: 0.021273\n",
      "\n",
      "Training set: Accuracy: 56015/57000 (98.27%)\n",
      "Validation set: Accuracy: 2938/3000 (97.93%)\n",
      "\n",
      "Train Epoch: 3 [0/57000 (0.00%)]\tLoss: 0.092957\n",
      "Train Epoch: 3 [19200/57000 (33.67%)]\tLoss: 0.069989\n",
      "Train Epoch: 3 [38400/57000 (67.34%)]\tLoss: 0.012819\n",
      "\n",
      "Training set: Accuracy: 56203/57000 (98.60%)\n",
      "Validation set: Accuracy: 2950/3000 (98.33%)\n",
      "\n",
      "Train Epoch: 4 [0/57000 (0.00%)]\tLoss: 0.095343\n",
      "Train Epoch: 4 [19200/57000 (33.67%)]\tLoss: 0.058880\n",
      "Train Epoch: 4 [38400/57000 (67.34%)]\tLoss: 0.013601\n",
      "\n",
      "Training set: Accuracy: 56359/57000 (98.88%)\n",
      "Validation set: Accuracy: 2960/3000 (98.67%)\n",
      "\n",
      "Train Epoch: 5 [0/57000 (0.00%)]\tLoss: 0.060803\n",
      "Train Epoch: 5 [19200/57000 (33.67%)]\tLoss: 0.037114\n",
      "Train Epoch: 5 [38400/57000 (67.34%)]\tLoss: 0.012941\n",
      "\n",
      "Training set: Accuracy: 56468/57000 (99.07%)\n",
      "Validation set: Accuracy: 2961/3000 (98.70%)\n",
      "\n",
      "Train Epoch: 6 [0/57000 (0.00%)]\tLoss: 0.047566\n",
      "Train Epoch: 6 [19200/57000 (33.67%)]\tLoss: 0.036562\n",
      "Train Epoch: 6 [38400/57000 (67.34%)]\tLoss: 0.006527\n",
      "\n",
      "Training set: Accuracy: 56545/57000 (99.20%)\n",
      "Validation set: Accuracy: 2960/3000 (98.67%)\n",
      "\n",
      "Train Epoch: 7 [0/57000 (0.00%)]\tLoss: 0.044151\n",
      "Train Epoch: 7 [19200/57000 (33.67%)]\tLoss: 0.009602\n",
      "Train Epoch: 7 [38400/57000 (67.34%)]\tLoss: 0.005882\n",
      "\n",
      "Training set: Accuracy: 56607/57000 (99.31%)\n",
      "Validation set: Accuracy: 2953/3000 (98.43%)\n",
      "\n",
      "Train Epoch: 8 [0/57000 (0.00%)]\tLoss: 0.076895\n",
      "Train Epoch: 8 [19200/57000 (33.67%)]\tLoss: 0.004415\n",
      "Train Epoch: 8 [38400/57000 (67.34%)]\tLoss: 0.008990\n",
      "\n",
      "Training set: Accuracy: 56636/57000 (99.36%)\n",
      "Validation set: Accuracy: 2967/3000 (98.90%)\n",
      "\n",
      "Train Epoch: 9 [0/57000 (0.00%)]\tLoss: 0.037113\n",
      "Train Epoch: 9 [19200/57000 (33.67%)]\tLoss: 0.003775\n",
      "Train Epoch: 9 [38400/57000 (67.34%)]\tLoss: 0.024793\n",
      "\n",
      "Training set: Accuracy: 56677/57000 (99.43%)\n",
      "Validation set: Accuracy: 2960/3000 (98.67%)\n",
      "\n",
      "Train Epoch: 10 [0/57000 (0.00%)]\tLoss: 0.014503\n",
      "Train Epoch: 10 [19200/57000 (33.67%)]\tLoss: 0.000317\n",
      "Train Epoch: 10 [38400/57000 (67.34%)]\tLoss: 0.007163\n",
      "\n",
      "Training set: Accuracy: 56703/57000 (99.48%)\n",
      "Validation set: Accuracy: 2962/3000 (98.73%)\n",
      "\n",
      "Train Epoch: 11 [0/57000 (0.00%)]\tLoss: 0.011806\n",
      "Train Epoch: 11 [19200/57000 (33.67%)]\tLoss: 0.001418\n",
      "Train Epoch: 11 [38400/57000 (67.34%)]\tLoss: 0.027468\n",
      "\n",
      "Training set: Accuracy: 56713/57000 (99.50%)\n",
      "Validation set: Accuracy: 2962/3000 (98.73%)\n",
      "\n",
      "Train Epoch: 12 [0/57000 (0.00%)]\tLoss: 0.022656\n",
      "Train Epoch: 12 [19200/57000 (33.67%)]\tLoss: 0.002234\n",
      "Train Epoch: 12 [38400/57000 (67.34%)]\tLoss: 0.001284\n",
      "\n",
      "Training set: Accuracy: 56788/57000 (99.63%)\n",
      "Validation set: Accuracy: 2964/3000 (98.80%)\n",
      "\n",
      "Train Epoch: 13 [0/57000 (0.00%)]\tLoss: 0.030942\n",
      "Train Epoch: 13 [19200/57000 (33.67%)]\tLoss: 0.005043\n",
      "Train Epoch: 13 [38400/57000 (67.34%)]\tLoss: 0.001201\n",
      "\n",
      "Training set: Accuracy: 56750/57000 (99.56%)\n",
      "Validation set: Accuracy: 2962/3000 (98.73%)\n",
      "\n",
      "Train Epoch: 14 [0/57000 (0.00%)]\tLoss: 0.045800\n",
      "Train Epoch: 14 [19200/57000 (33.67%)]\tLoss: 0.000354\n",
      "Train Epoch: 14 [38400/57000 (67.34%)]\tLoss: 0.015462\n",
      "\n",
      "Training set: Accuracy: 56777/57000 (99.61%)\n",
      "Validation set: Accuracy: 2960/3000 (98.67%)\n",
      "\n",
      "Test set: Accuracy: 59620/60000 (99.37%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network = Model_2().to(device)\n",
    "rlt_const = training(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791b1471",
   "metadata": {},
   "source": [
    "## 9. 두모델의 성능을 비교하시오"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f8156f",
   "metadata": {},
   "source": [
    "정답) relu가 sigmoid에 비해 vanishing gradient가 적기때문에 더 뛰어난 성능을 보인다. relu가 sigmoid에 비해 빠르게 좋은 성능으로 수렴한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
